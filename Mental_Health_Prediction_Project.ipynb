{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devij321-coder/EDA-project/blob/main/Mental_Health_Prediction_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKU7gCyrUL1J"
      },
      "source": [
        "#Library and Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Libraries:\n",
        "import datasets as weightDay\n",
        "import datasets as sleepDay\n",
        "import datasets as stepsW\n",
        "import datasets as stepN\n",
        "import datasets as MetsN\n",
        "import datasets as minCaloriesW\n",
        "Import datasets as minuteCaloriesNarrow\n",
        "Import datasets as hourlysteps\n",
        "import datasets as hourlyCalories\n",
        "import datasets as heartrate\n",
        "import datasets as dailysteps\n",
        "import datasets as dailyintensities\n",
        "import datasets as dailyCalories\n",
        "import datasets as dailyactivity\n",
        "import datasets as cudakeyring\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Dataset Rows & Columns count\n",
        "rows, columns = data.shape\n",
        "print(\"Number of rows:\", rows)\n",
        "print(\"Number of columns:\", columns)\n",
        "print(\"Columns:\", data.columns.tolist())\n",
        "print(\"Rows:\", data.index.tolist())"
      ],
      "metadata": {
        "collapsed": true,
        "id": "vze5U2WXToTy"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "rows, columns = data.shape\n",
        "print(\"Number of rows:\", rows)\n",
        "print(\"Number of columns:\", columns)\n",
        "print(\"Columns:\", data.columns.tolist())\n",
        "print(\"Rows:\", data.index.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "collapsed": true,
        "id": "arCXdaNsT5ob",
        "outputId": "ba92cfe1-25ad-4c4f-f687-4a6cdbd53ae0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-139003492.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Dataset Rows & Columns count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of rows:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of columns:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Columns:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "5XbrHhtLU8B4",
        "outputId": "582d2a37-65a7-43bc-d2c6-ecd3836015b0",
        "collapsed": true
      },
      "source": [
        "data = pd.read_csv(\"Mental_health_prediction.csv\")\n",
        "    print(\"Successfully loaded Mental_health_prediction.csv\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: Mental_health_prediction.csv not found. Please upload the file or check the path.\")\n",
        "\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unexpected indent (ipython-input-2260816551.py, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-2260816551.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    print(\"Successfully loaded Mental_health_prediction.csv\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rYK-LxbdcfqM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1DS8wCF8cDcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIVsuSklXTWM"
      },
      "source": [
        "train_df = pd.read_csv('survey.csv')\n",
        "print(train_df.shape)\n",
        "print(train_df.describe())\n",
        "print(train_df.info())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPKx4y5QX5by"
      },
      "source": [
        "#Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "nGGtUHo5XzvX",
        "outputId": "523ba826-c0f2-49be-d28b-8b023e51f840"
      },
      "source": [
        "#missing data\n",
        "total = train_df.isnull().sum().sort_values(ascending=False)\n",
        "percent = (train_df.isnull().sum()/train_df.isnull().count()).sort_values(ascending=False)\n",
        "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
        "missing_data.head(20)\n",
        "print(missing_data)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2214946652.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#missing data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpercent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmissing_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Total'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Percent'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmissing_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZL7prT6X-7T"
      },
      "source": [
        "#dealing with missing data\n",
        "train_df.drop(['comments'], axis= 1, inplace=True)\n",
        "train_df.drop(['state'], axis= 1, inplace=True)\n",
        "train_df.drop(['Timestamp'], axis= 1, inplace=True)\n",
        "\n",
        "train_df.isnull().sum().max() #just checking that there's no missing data missing...\n",
        "train_df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEJ01-IbYagP"
      },
      "source": [
        "Cleaning NaN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "hI4SbkGXYTp_",
        "outputId": "52a32073-6528-4b08-ff6e-2f9afaa0b69e"
      },
      "source": [
        "# Assign default values for each data type\n",
        "defaultInt = 0\n",
        "defaultString = 'NaN'\n",
        "defaultFloat = 0.0\n",
        "\n",
        "# Create lists by data tpe\n",
        "intFeatures = ['Age']\n",
        "stringFeatures = ['Gender', 'Country', 'self_employed', 'family_history', 'treatment', 'work_interfere',\n",
        "                 'no_employees', 'remote_work', 'tech_company', 'anonymity', 'leave', 'mental_health_consequence',\n",
        "                 'phys_health_consequence', 'coworkers', 'supervisor', 'mental_health_interview', 'phys_health_interview',\n",
        "                 'mental_vs_physical', 'obs_consequence', 'benefits', 'care_options', 'wellness_program',\n",
        "                 'seek_help']\n",
        "floatFeatures = []\n",
        "\n",
        "# Clean the NaN's\n",
        "for feature in train_df:\n",
        "    if feature in intFeatures:\n",
        "        train_df[feature] = train_df[feature].fillna(defaultInt)\n",
        "    elif feature in stringFeatures:\n",
        "        train_df[feature] = train_df[feature].fillna(defaultString)\n",
        "    elif feature in floatFeatures:\n",
        "        train_df[feature] = train_df[feature].fillna(defaultFloat)\n",
        "    else:\n",
        "        print('Error: Feature %s not recognized.' % feature)\n",
        "train_df.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2010282806.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Clean the NaN's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mintFeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaultInt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAgJLUoBYzHI"
      },
      "source": [
        "#Clean 'Gender'\n",
        "gender = train_df['Gender'].unique()\n",
        "print(gender)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "ci8qNBlHZWjt",
        "outputId": "4856b9ff-fb8a-483b-ecd4-1d0ab89d52a9"
      },
      "source": [
        "#Made gender groups\n",
        "male_str = [\"male\", \"m\", \"male-ish\", \"maile\", \"mal\", \"male (cis)\", \"make\", \"male \", \"man\",\"msle\", \"mail\", \"malr\",\"cis man\", \"Cis Male\", \"cis male\"]\n",
        "trans_str = [\"trans-female\", \"something kinda male?\", \"queer/she/they\", \"non-binary\",\"nah\", \"all\", \"enby\", \"fluid\", \"genderqueer\", \"androgyne\", \"agender\", \"male leaning androgynous\", \"guy (-ish) ^_^\", \"trans woman\", \"neuter\", \"female (trans)\", \"queer\", \"ostensibly male, unsure what that really means\"]\n",
        "female_str = [\"cis female\", \"f\", \"female\", \"woman\",  \"femake\", \"female \",\"cis-female/femme\", \"female (cis)\", \"femail\"]\n",
        "\n",
        "for (row, col) in train_df.iterrows():\n",
        "\n",
        "    if str.lower(col.Gender) in male_str:\n",
        "        train_df['Gender'].replace(to_replace=col.Gender, value='male', inplace=True)\n",
        "\n",
        "    if str.lower(col.Gender) in female_str:\n",
        "        train_df['Gender'].replace(to_replace=col.Gender, value='female', inplace=True)\n",
        "\n",
        "    if str.lower(col.Gender) in trans_str:\n",
        "        train_df['Gender'].replace(to_replace=col.Gender, value='trans', inplace=True)\n",
        "\n",
        "#Get rid of bullshit\n",
        "stk_list = ['A little about you', 'p']\n",
        "train_df = train_df[~train_df['Gender'].isin(stk_list)]\n",
        "\n",
        "print(train_df['Gender'].unique())"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-68544508.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfemale_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"cis female\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"f\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"female\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"woman\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m\"femake\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"female \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"cis-female/femme\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"female (cis)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"femail\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGender\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmale_str\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LytRp-MiZ3WM"
      },
      "source": [
        "#complete missing age with mean\n",
        "train_df['Age'].fillna(train_df['Age'].median(), inplace = True)\n",
        "\n",
        "# Fill with media() values < 18 and > 120\n",
        "s = pd.Series(train_df['Age'])\n",
        "s[s<18] = train_df['Age'].median()\n",
        "train_df['Age'] = s\n",
        "s = pd.Series(train_df['Age'])\n",
        "s[s>120] = train_df['Age'].median()\n",
        "train_df['Age'] = s\n",
        "\n",
        "#Ranges of Age\n",
        "train_df['age_range'] = pd.cut(train_df['Age'], [0,20,30,65,100], labels=[\"0-20\", \"21-30\", \"31-65\", \"66-100\"], include_lowest=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-a4jIjqfaAsQ"
      },
      "source": [
        "#There are only 0.014% of self employed so let's change NaN to NOT self_employed\n",
        "#Replace \"NaN\" string from defaultString\n",
        "train_df['self_employed'] = train_df['self_employed'].replace([defaultString], 'No')\n",
        "print(train_df['self_employed'].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "dlH2JMtjaI96",
        "outputId": "f8e8fd13-492a-47e0-b395-311a0c6db770"
      },
      "source": [
        "#There are only 0.20% of self work_interfere so let's change NaN to \"Don't know\n",
        "#Replace \"NaN\" string from defaultString\n",
        "\n",
        "train_df['work_interfere'] = train_df['work_interfere'].replace([defaultString], 'Don\\'t know' )\n",
        "print(train_df['work_interfere'].unique())"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2467000427.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#Replace \"NaN\" string from defaultString\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'work_interfere'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'work_interfere'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdefaultString\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Don\\'t know'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'work_interfere'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU9sRPnQaP2D"
      },
      "source": [
        "#Encoding Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrFCOYpSaNrL"
      },
      "source": [
        "#Encoding data\n",
        "labelDict = {}\n",
        "for feature in train_df:\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    le.fit(train_df[feature])\n",
        "    le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
        "    train_df[feature] = le.transform(train_df[feature])\n",
        "    # Get labels\n",
        "    labelKey = 'label_' + feature\n",
        "    labelValue = [*le_name_mapping]\n",
        "    labelDict[labelKey] =labelValue\n",
        "\n",
        "for key, value in labelDict.items():\n",
        "    print(key, value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eBE2WLmaX96"
      },
      "source": [
        "#Get rid of 'Country'\n",
        "train_df = train_df.drop(['Country'], axis= 1)\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DNKbr_TajZa"
      },
      "source": [
        "Testing there aren't any missing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "cxlJqy9KadVC",
        "outputId": "73b11f18-82af-4391-a635-5d0002fdd417"
      },
      "source": [
        "#missing data\n",
        "total = train_df.isnull().sum().sort_values(ascending=False)\n",
        "percent = (train_df.isnull().sum()/train_df.isnull().count()).sort_values(ascending=False)\n",
        "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
        "missing_data.head(20)\n",
        "print(missing_data)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2214946652.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#missing data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpercent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmissing_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Total'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Percent'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmissing_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UERrfJsnatzt"
      },
      "source": [
        "Features Scaling: We're going to scale age, because it is extremely different from the other ones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoJ-Ori9avcR"
      },
      "source": [
        "#Covariance Matrix. Variability comparison between categories of variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INZUJIV0antX"
      },
      "source": [
        "#correlation matrix\n",
        "corrmat = train_df.corr()\n",
        "f, ax = plt.subplots(figsize=(12, 9))\n",
        "sns.heatmap(corrmat, vmax=.8, square=True);\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg1Y03-5bCVb"
      },
      "source": [
        "#treatment correlation matrix\n",
        "k = 10 #number of variables for heatmap\n",
        "cols = corrmat.nlargest(k, 'treatment')['treatment'].index\n",
        "cm = np.corrcoef(train_df[cols].values.T)\n",
        "sns.set(font_scale=1.25)\n",
        "hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFd3XHrUbpj_"
      },
      "source": [
        "#Some charts to see data relationship"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nf2HeCribtJ4"
      },
      "source": [
        "**Distribution** and density by Age"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geuI-6OMbGez"
      },
      "source": [
        "# Distribution and density by Age\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.distplot(train_df[\"Age\"], bins=24)\n",
        "plt.title(\"Distribution and density by Age\")\n",
        "plt.xlabel(\"Age\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laO_IxDPb2cg"
      },
      "source": [
        "Separate by treatment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "fbpapqAAbxDh",
        "outputId": "ffe5ac0a-7040-41be-fa33-4b6c80802f77"
      },
      "source": [
        "g = sns.FacetGrid(train_df, col='treatment', height=5)\n",
        "g = g.map(sns.distplot, \"Age\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1318471631.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFacetGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'treatment'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Age\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gx9Jwxbwb-Pl"
      },
      "source": [
        "How many people has been treated?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syKkijhCb5tk"
      },
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "labels = labelDict['label_Gender']\n",
        "g = sns.countplot(x=\"treatment\", data=train_df)\n",
        "g.set_xticklabels(labels)\n",
        "\n",
        "plt.title('Total Distribution by treated or not')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9h-iNvccKcD"
      },
      "source": [
        "Nested barplot to show probabilities for class and sex"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "yZli5FghcBwt",
        "outputId": "7b35ba4d-1599-4491-d64c-d11bebcffbdc"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'labelDict', 'train_df', 'o', and 'new_labels' are already defined\n",
        "o = labelDict['label_age_range']\n",
        "\n",
        "g = sns.catplot(x=\"age_range\", y=\"treatment\", hue=\"Gender\", data=train_df, kind=\"bar\", ci=None, height=5, aspect=2, legend_out=True)\n",
        "g.set_xticklabels(o)\n",
        "\n",
        "plt.title('Probability of mental health condition')\n",
        "plt.ylabel('Probability x 100')\n",
        "plt.xlabel('Age')\n",
        "\n",
        "# Replace legend labels\n",
        "new_labels = labelDict['label_Gender']\n",
        "for t, l in zip(g._legend.texts, new_labels):\n",
        "    t.set_text(l)\n",
        "\n",
        "# Positioning the legend\n",
        "g.fig.subplots_adjust(top=0.9, right=0.8)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'labelDict' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2764702613.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Assuming 'labelDict', 'train_df', 'o', and 'new_labels' are already defined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabelDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label_age_range'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"age_range\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"treatment\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Gender\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bar\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mci\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegend_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'labelDict' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmthbxoXcYE1"
      },
      "source": [
        "Barplot to show probabilities for family history"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "UoUsvFVRcPe2",
        "outputId": "4e2df394-1fd7-44a2-b415-a7c0b0f6a1db"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'labelDict', 'train_df', 'o', and 'new_labels' are already defined\n",
        "o = labelDict['label_family_history']\n",
        "\n",
        "g = sns.catplot(x=\"family_history\", y=\"treatment\", hue=\"Gender\", data=train_df, kind=\"bar\", ci=None, height=5, aspect=2, legend_out=True)\n",
        "g.set_xticklabels(o)\n",
        "\n",
        "g.set_axis_labels('Family History', 'Probability x 100')  # Instead of plt.xlabel and plt.ylabel\n",
        "plt.title('Probability of mental health condition')\n",
        "\n",
        "# Replace legend labels\n",
        "new_labels = labelDict['label_Gender']\n",
        "for t, l in zip(g._legend.texts, new_labels):\n",
        "    t.set_text(l)\n",
        "\n",
        "# Positioning the legend\n",
        "g.fig.subplots_adjust(top=0.9, right=0.8)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'labelDict' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4252529051.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Assuming 'labelDict', 'train_df', 'o', and 'new_labels' are already defined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabelDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label_family_history'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"family_history\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"treatment\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Gender\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bar\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mci\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegend_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'labelDict' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fqj4LICwcgrN"
      },
      "source": [
        "Barplot to show probabilities for care options"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKB-tQO3cbq_"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'labelDict', 'train_df', 'o', and 'new_labels' are already defined\n",
        "o = labelDict['label_care_options']\n",
        "\n",
        "g = sns.catplot(x=\"care_options\", y=\"treatment\", hue=\"Gender\", data=train_df, kind=\"bar\", ci=None, height=5, aspect=2, legend_out=True)\n",
        "g.set_xticklabels(o)\n",
        "\n",
        "g.set_axis_labels('Care options', 'Probability x 100')  # Instead of plt.xlabel and plt.ylabel\n",
        "plt.title('Probability of mental health condition')\n",
        "\n",
        "# Replace legend labels\n",
        "new_labels = labelDict['label_Gender']\n",
        "for t, l in zip(g._legend.texts, new_labels):\n",
        "    t.set_text(l)\n",
        "\n",
        "# Positioning the legend\n",
        "g.fig.subplots_adjust(top=0.9, right=0.8)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oukVHMQwcozL"
      },
      "source": [
        "Barplot to show probabilities for benefits\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW3ykFSYckMt"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming labelDict and train_df are already defined\n",
        "o = labelDict['label_benefits']\n",
        "\n",
        "# Using sns.catplot instead of sns.factorplot\n",
        "g = sns.catplot(x=\"care_options\", y=\"treatment\", hue=\"Gender\", data=train_df, kind=\"bar\", ci=None, height=5, aspect=2, legend_out=True)\n",
        "\n",
        "# Set x-tick labels\n",
        "plt.xticks(ticks=g.ax.get_xticks(), labels=o)\n",
        "\n",
        "plt.title('Probability of mental health condition')\n",
        "plt.ylabel('Probability x 100')\n",
        "plt.xlabel('Benefits')\n",
        "\n",
        "# Replace legend labels\n",
        "new_labels = labelDict['label_Gender']\n",
        "for t, l in zip(g._legend.texts, new_labels):\n",
        "    t.set_text(l)\n",
        "\n",
        "# Positioning the legend\n",
        "g.fig.subplots_adjust(top=0.9, right=0.8)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6CnGdrrcwqU"
      },
      "source": [
        "Barplot to show probabilities for work interfere\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQVddZv3ctIZ"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming labelDict and train_df are already defined\n",
        "o = labelDict['label_work_interfere']\n",
        "\n",
        "# Using sns.catplot instead of sns.factorplot\n",
        "g = sns.catplot(x=\"work_interfere\", y=\"treatment\", hue=\"Gender\", data=train_df, kind=\"bar\", ci=None, height=5, aspect=2, legend_out=True)\n",
        "\n",
        "# Set x-tick labels\n",
        "g.set_xticklabels(o)\n",
        "\n",
        "plt.title('Probability of mental health condition')\n",
        "plt.ylabel('Probability x 100')\n",
        "plt.xlabel('Work interfere')\n",
        "\n",
        "# Replace legend labels\n",
        "new_labels = labelDict['label_Gender']\n",
        "for t, l in zip(g._legend.texts, new_labels):\n",
        "    t.set_text(l)\n",
        "\n",
        "# Positioning the legend\n",
        "g.fig.subplots_adjust(top=0.9, right=0.8)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaJjYfbtc7S3"
      },
      "source": [
        "#Scaling and Fitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSN4p5CWc_4z"
      },
      "source": [
        "Features Scaling We're going to scale age, because is extremely different from the othere ones.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "E8CEx69mc0Ff",
        "outputId": "7782b8a1-a8fc-4f93-f75c-4d86c6e80890"
      },
      "source": [
        "# Scaling Age\n",
        "scaler = MinMaxScaler()\n",
        "train_df['Age'] = scaler.fit_transform(train_df[['Age']])\n",
        "train_df.head()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'MinMaxScaler' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1804840269.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Scaling Age\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Age'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Age'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'MinMaxScaler' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emP7M76leCr2"
      },
      "source": [
        "Spilitting Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4PCK9kudFlM"
      },
      "source": [
        "# define X and y\n",
        "feature_cols = ['Age', 'Gender', 'family_history', 'benefits', 'care_options', 'anonymity', 'leave', 'work_interfere']\n",
        "X = train_df[feature_cols]\n",
        "y = train_df.treatment\n",
        "\n",
        "# split X and y into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "# Create dictionaries for final graph\n",
        "# Use: methodDict['Stacking'] = accuracy_score\n",
        "methodDict = {}\n",
        "rmseDict = ()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ-Fn4EeeJ7v"
      },
      "source": [
        "# Build a forest and compute the feature importances\n",
        "forest = ExtraTreesClassifier(n_estimators=250,\n",
        "                              random_state=0)\n",
        "\n",
        "forest.fit(X, y)\n",
        "importances = forest.feature_importances_\n",
        "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
        "             axis=0)\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "labels = []\n",
        "for f in range(X.shape[1]):\n",
        "    labels.append(feature_cols[f])\n",
        "\n",
        "# Plot the feature importances of the forest\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.title(\"Feature importances\")\n",
        "plt.bar(range(X.shape[1]), importances[indices],\n",
        "       color=\"r\", yerr=std[indices], align=\"center\")\n",
        "plt.xticks(range(X.shape[1]), labels, rotation='vertical')\n",
        "plt.xlim([-1, X.shape[1]])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2wG6BfSeSVo"
      },
      "source": [
        "#Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqq2ECp2eOKh"
      },
      "source": [
        "def evalClassModel(model, y_test, y_pred_class, plot=False):\n",
        "    #Classification accuracy: percentage of correct predictions\n",
        "    # calculate accuracy\n",
        "    print('Accuracy:', metrics.accuracy_score(y_test, y_pred_class))\n",
        "\n",
        "    #Null accuracy: accuracy that could be achieved by always predicting the most frequent class\n",
        "    # examine the class distribution of the testing set (using a Pandas Series method)\n",
        "    print('Null accuracy:\\n', y_test.value_counts())\n",
        "\n",
        "    # calculate the percentage of ones\n",
        "    print('Percentage of ones:', y_test.mean())\n",
        "\n",
        "    # calculate the percentage of zeros\n",
        "    print('Percentage of zeros:',1 - y_test.mean())\n",
        "\n",
        "    #Comparing the true and predicted response values\n",
        "    print('True:', y_test.values[0:25])\n",
        "    print('Pred:', y_pred_class[0:25])\n",
        "\n",
        "    #Confusion matrix\n",
        "    # save confusion matrix and slice into four pieces\n",
        "    confusion = metrics.confusion_matrix(y_test, y_pred_class)\n",
        "    #[row, column]\n",
        "    TP = confusion[1, 1]\n",
        "    TN = confusion[0, 0]\n",
        "    FP = confusion[0, 1]\n",
        "    FN = confusion[1, 0]\n",
        "\n",
        "    # visualize Confusion Matrix\n",
        "    sns.heatmap(confusion,annot=True,fmt=\"d\")\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.show()\n",
        "\n",
        "    #Metrics computed from a confusion matrix\n",
        "    #Classification Accuracy: Overall, how often is the classifier correct?\n",
        "    accuracy = metrics.accuracy_score(y_test, y_pred_class)\n",
        "    print('Classification Accuracy:', accuracy)\n",
        "\n",
        "    #Classification Error: Overall, how often is the classifier incorrect?\n",
        "    print('Classification Error:', 1 - metrics.accuracy_score(y_test, y_pred_class))\n",
        "\n",
        "    #False Positive Rate: When the actual value is negative, how often is the prediction incorrect?\n",
        "    false_positive_rate = FP / float(TN + FP)\n",
        "    print('False Positive Rate:', false_positive_rate)\n",
        "\n",
        "    #Precision: When a positive value is predicted, how often is the prediction correct?\n",
        "    print('Precision:', metrics.precision_score(y_test, y_pred_class))\n",
        "\n",
        "\n",
        "    # IMPORTANT: first argument is true values, second argument is predicted probabilities\n",
        "    print('AUC Score:', metrics.roc_auc_score(y_test, y_pred_class))\n",
        "\n",
        "    # calculate cross-validated AUC\n",
        "    print('Cross-validated AUC:', cross_val_score(model, X, y, cv=10, scoring='roc_auc').mean())\n",
        "\n",
        "    ##########################################\n",
        "    #Adjusting the classification threshold\n",
        "    ##########################################\n",
        "    # print the first 10 predicted responses\n",
        "    print('First 10 predicted responses:\\n', model.predict(X_test)[0:10])\n",
        "\n",
        "    # print the first 10 predicted probabilities of class membership\n",
        "    print('First 10 predicted probabilities of class members:\\n', model.predict_proba(X_test)[0:10])\n",
        "\n",
        "    # print the first 10 predicted probabilities for class 1\n",
        "    model.predict_proba(X_test)[0:10, 1]\n",
        "\n",
        "    # store the predicted probabilities for class 1\n",
        "    y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    if plot == True:\n",
        "        # histogram of predicted probabilities\n",
        "        plt.rcParams['font.size'] = 12\n",
        "        plt.hist(y_pred_prob, bins=8)\n",
        "\n",
        "        # x-axis limit from 0 to 1\n",
        "        plt.xlim(0,1)\n",
        "        plt.title('Histogram of predicted probabilities')\n",
        "        plt.xlabel('Predicted probability of treatment')\n",
        "        plt.ylabel('Frequency')\n",
        "\n",
        "\n",
        "    # predict treatment if the predicted probability is greater than 0.3\n",
        "    # it will return 1 for all values above 0.3 and 0 otherwise\n",
        "    # results are 2D so we slice out the first column\n",
        "    y_pred_prob = y_pred_prob.reshape(-1,1)\n",
        "    y_pred_class = binarize(y_pred_prob, 0.3)[0]\n",
        "\n",
        "    # print the first 10 predicted probabilities\n",
        "    print('First 10 predicted probabilities:\\n', y_pred_prob[0:10])\n",
        "\n",
        "    ##########################################\n",
        "    #ROC Curves and Area Under the Curve (AUC)\n",
        "    ##########################################\n",
        "\n",
        "    #AUC is the percentage of the ROC plot that is underneath the curve\n",
        "    #Higher value = better classifier\n",
        "    roc_auc = metrics.roc_auc_score(y_test, y_pred_prob)\n",
        "\n",
        "\n",
        "\n",
        "    # IMPORTANT: first argument is true values, second argument is predicted probabilities\n",
        "    # roc_curve returns 3 objects fpr, tpr, thresholds\n",
        "    # fpr: false positive rate\n",
        "    # tpr: true positive rate\n",
        "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_prob)\n",
        "    if plot == True:\n",
        "        plt.figure()\n",
        "\n",
        "        plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "        plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.0])\n",
        "        plt.rcParams['font.size'] = 12\n",
        "        plt.title('ROC curve for treatment classifier')\n",
        "        plt.xlabel('False Positive Rate (1 - Specificity)')\n",
        "        plt.ylabel('True Positive Rate (Sensitivity)')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.show()\n",
        "\n",
        "    # define a function that accepts a threshold and prints sensitivity and specificity\n",
        "    def evaluate_threshold(threshold):\n",
        "        #Sensitivity: When the actual value is positive, how often is the prediction correct?\n",
        "        #Specificity: When the actual value is negative, how often is the prediction correct?print('Sensitivity for ' + str(threshold) + ' :', tpr[thresholds > threshold][-1])\n",
        "        print('Specificity for ' + str(threshold) + ' :', 1 - fpr[thresholds > threshold][-1])\n",
        "\n",
        "    # One way of setting threshold\n",
        "    predict_mine = np.where(y_pred_prob > 0.50, 1, 0)\n",
        "    confusion = metrics.confusion_matrix(y_test, predict_mine)\n",
        "    print(confusion)\n",
        "\n",
        "\n",
        "\n",
        "    return accuracy"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7tGbmc4fW9C"
      },
      "source": [
        "Tuning with cross validation score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9Y7NReefTiV"
      },
      "source": [
        "def tuningCV(knn):\n",
        "\n",
        "    # search for an optimal value of K for KNN\n",
        "    k_range = list(range(1, 31))\n",
        "    k_scores = []\n",
        "    for k in k_range:\n",
        "        knn = KNeighborsClassifier(n_neighbors=k)\n",
        "        scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
        "        k_scores.append(scores.mean())\n",
        "    print(k_scores)\n",
        "    # plot the value of K for KNN (x-axis) versus the cross-validated accuracy (y-axis)\n",
        "    plt.plot(k_range, k_scores)\n",
        "    plt.xlabel('Value of K for KNN')\n",
        "    plt.ylabel('Cross-Validated Accuracy')\n",
        "    plt.show()"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYytocEofeOE"
      },
      "source": [
        "Tuning with GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjE6ARIYfbkd"
      },
      "source": [
        "def tuningGridSerach(knn):\n",
        "    #More efficient parameter tuning using GridSearchCV\n",
        "    k_range = list(range(1, 31))\n",
        "    print(k_range)\n",
        "\n",
        "    # create a parameter grid: map the parameter names to the values that should be searched\n",
        "    param_grid = dict(n_neighbors=k_range)\n",
        "    print(param_grid)\n",
        "\n",
        "    # instantiate the grid\n",
        "    grid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy')\n",
        "\n",
        "    # fit the grid with data\n",
        "    grid.fit(X, y)\n",
        "\n",
        "    # view the complete results (list of named tuples)\n",
        "    grid.grid_scores_\n",
        "\n",
        "    # examine the first tuple\n",
        "    print(grid.grid_scores_[0].parameters)\n",
        "    print(grid.grid_scores_[0].cv_validation_scores)\n",
        "    print(grid.grid_scores_[0].mean_validation_score)\n",
        "\n",
        "    # create a list of the mean scores only\n",
        "    grid_mean_scores = [result.mean_validation_score for result in grid.grid_scores_]\n",
        "    print(grid_mean_scores)\n",
        "\n",
        "    # plot the results\n",
        "    plt.plot(k_range, grid_mean_scores)\n",
        "    plt.xlabel('Value of K for KNN')\n",
        "    plt.ylabel('Cross-Validated Accuracy')\n",
        "    plt.show()\n",
        "\n",
        "    # examine the best model\n",
        "    print('GridSearch best score', grid.best_score_)\n",
        "    print('GridSearch best params', grid.best_params_)\n",
        "    print('GridSearch best estimator', grid.best_estimator_)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFhg6D_wfrUt"
      },
      "source": [
        "Tuning with RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrfBM1XUfoxf"
      },
      "source": [
        "def tuningRandomizedSearchCV(model, param_dist):\n",
        "    #Searching multiple parameters simultaneously\n",
        "    # n_iter controls the number of searches\n",
        "    rand = RandomizedSearchCV(model, param_dist, cv=10, scoring='accuracy', n_iter=10, random_state=5)\n",
        "    rand.fit(X, y)\n",
        "    rand.cv_results_\n",
        "\n",
        "    # examine the best model\n",
        "    print('Rand. Best Score: ', rand.best_score_)\n",
        "    print('Rand. Best Params: ', rand.best_params_)\n",
        "\n",
        "    # run RandomizedSearchCV 20 times (with n_iter=10) and record the best score\n",
        "    best_scores = []\n",
        "    for _ in range(20):\n",
        "        rand = RandomizedSearchCV(model, param_dist, cv=10, scoring='accuracy', n_iter=10)\n",
        "        rand.fit(X, y)\n",
        "        best_scores.append(round(rand.best_score_, 3))\n",
        "    print(best_scores)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzaS7F-vfzeV"
      },
      "source": [
        "Tuning with searching multiple parameters simultaneously"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeSKD8Abfw94"
      },
      "source": [
        "def tuningMultParam(knn):\n",
        "\n",
        "    #Searching multiple parameters simultaneously\n",
        "    # define the parameter values that should be searched\n",
        "    k_range = list(range(1, 31))\n",
        "    weight_options = ['uniform', 'distance']\n",
        "\n",
        "    # create a parameter grid: map the parameter names to the values that should be searched\n",
        "    param_grid = dict(n_neighbors=k_range, weights=weight_options)\n",
        "    print(param_grid)\n",
        "\n",
        "    # instantiate and fit the grid\n",
        "    grid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy')\n",
        "    grid.fit(X, y)\n",
        "\n",
        "    # view the complete results\n",
        "    print(grid.grid_scores_)\n",
        "\n",
        "    # examine the best model\n",
        "    print('Multiparam. Best Score: ', grid.best_score_)\n",
        "    print('Multiparam. Best Params: ', grid.best_params_)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNWD9dq3f8Ef"
      },
      "source": [
        "#Evaluating models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_f2FmsFZf94S"
      },
      "source": [
        "Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMZS5dMKf5vw"
      },
      "source": [
        "def logisticRegression():\n",
        "    # train a logistic regression model on the training set\n",
        "    logreg = LogisticRegression()\n",
        "    logreg.fit(X_train, y_train)\n",
        "\n",
        "    # make class predictions for the testing set\n",
        "    y_pred_class = logreg.predict(X_test)\n",
        "\n",
        "    accuracy_score = evalClassModel(logreg, y_test, y_pred_class, True)\n",
        "\n",
        "    #Data for final graph\n",
        "    methodDict['Log. Regression'] = accuracy_score * 100\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGt-pyy9gHF1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "58212ee2-6837-4971-f34b-b1a91babf6fc"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def logisticRegression(X_train, X_test, y_train, y_test):\n",
        "    # Train a logistic regression model on the training set\n",
        "    logreg = LogisticRegression()\n",
        "    logreg.fit(X_train, y_train)\n",
        "\n",
        "    # Make class predictions for the testing set\n",
        "    y_pred_class = logreg.predict(X_test)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred_class)\n",
        "    print(f'Accuracy: {accuracy:.2f}')\n",
        "\n",
        "    # Calculate the predicted probabilities\n",
        "    y_pred_proba = logreg.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Confusion Matrix\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred_class)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.show()\n",
        "\n",
        "    # Histogram of Predicted Probabilities\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.hist(y_pred_proba, bins=20, color='blue', edgecolor='black')\n",
        "    plt.title('Histogram of Predicted Probabilities')\n",
        "    plt.xlabel('Predicted Probability')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.show()\n",
        "\n",
        "    # ROC Curve\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    # Data for final graph\n",
        "    methodDict['Log. Regression'] = accuracy * 100\n",
        "\n",
        "# Example data (replace with your actual dataset)\n",
        "from sklearn.datasets import make_classification\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=2, n_redundant=10, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_test_split' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1120840605.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_classification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_informative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_redundant\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logisticRegression(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "dygMA-ZO-Sq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPH7c5ozgQrQ"
      },
      "source": [
        "KNeighbors Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIIpZmUkgKhz"
      },
      "source": [
        "def Knn():\n",
        "    # Calculating the best parameters\n",
        "    knn = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "    # define the parameter values that should be searched\n",
        "    k_range = list(range(1, 31))\n",
        "    weight_options = ['uniform', 'distance']\n",
        "\n",
        "    # specify \"parameter distributions\" rather than a \"parameter grid\"\n",
        "    param_dist = dict(n_neighbors=k_range, weights=weight_options)\n",
        "    tuningRandomizedSearchCV(knn, param_dist)\n",
        "\n",
        "    # train a KNeighborsClassifier model on the training set\n",
        "    knn = KNeighborsClassifier(n_neighbors=27, weights='uniform')\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    # make class predictions for the testing set\n",
        "    y_pred_class = knn.predict(X_test)\n",
        "\n",
        "    accuracy_score = evalClassModel(knn, y_test, y_pred_class, True)\n",
        "\n",
        "    #Data for final graph\n",
        "    methodDict['K-Neighbors'] = accuracy_score * 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NndcXu8LgcPZ"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def Knn(X_train, X_test, y_train, y_test):\n",
        "    # Train a KNeighborsClassifier model on the training set with the best parameters\n",
        "    knn = KNeighborsClassifier(n_neighbors=27, weights='uniform')\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    # Make class predictions for the testing set\n",
        "    y_pred_class = knn.predict(X_test)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred_class)\n",
        "    print(f'Accuracy: {accuracy:.2f}')\n",
        "\n",
        "    # Calculate the predicted probabilities\n",
        "    y_pred_proba = knn.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Confusion Matrix\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred_class)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.show()\n",
        "\n",
        "    # Histogram of Predicted Probabilities\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.hist(y_pred_proba, bins=20, color='blue', edgecolor='black')\n",
        "    plt.title('Histogram of Predicted Probabilities')\n",
        "    plt.xlabel('Predicted Probability')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.show()\n",
        "\n",
        "    # ROC Curve\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    # Data for final graph\n",
        "    methodDict['K-Neighbors'] = accuracy * 100\n",
        "\n",
        "# Example call to the function assuming X_train, X_test, y_train, y_test are defined\n",
        "# Knn(X_train, X_test, y_train, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Knn(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "L1U5r5_N9IEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATF-3ODii6IE"
      },
      "source": [
        "Decision Tree classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrbzKiXQgfIk"
      },
      "source": [
        "def treeClassifier():\n",
        "    # Calculating the best parameters\n",
        "    tree = DecisionTreeClassifier()\n",
        "    featuresSize = feature_cols.__len__()\n",
        "    param_dist = {\"max_depth\": [3, None],\n",
        "              \"max_features\": randint(1, featuresSize),\n",
        "              \"min_samples_split\": randint(2, 9),\n",
        "              \"min_samples_leaf\": randint(1, 9),\n",
        "              \"criterion\": [\"gini\", \"entropy\"]}\n",
        "    tuningRandomizedSearchCV(tree, param_dist)\n",
        "\n",
        "    # train a decision tree model on the training set\n",
        "    tree = DecisionTreeClassifier(max_depth=3, min_samples_split=8, max_features=6, criterion='entropy', min_samples_leaf=7)\n",
        "    tree.fit(X_train, y_train)\n",
        "\n",
        "    # make class predictions for the testing set\n",
        "    y_pred_class = tree.predict(X_test)\n",
        "\n",
        "    accuracy_score = evalClassModel(tree, y_test, y_pred_class, True)\n",
        "\n",
        "    #Data for final graph\n",
        "    methodDict['Decision Tree Classifier'] = accuracy_score * 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emMSj1I4jAus"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import randint\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Define a function to perform parameter tuning using RandomizedSearchCV\n",
        "def tuningRandomizedSearchCV(model, param_dist):\n",
        "    rand_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=100, cv=5, random_state=42)\n",
        "    rand_search.fit(X_train, y_train)\n",
        "    print(f\"Best parameters found: {rand_search.best_params_}\")\n",
        "    return rand_search.best_params_\n",
        "\n",
        "# Define the treeClassifier function\n",
        "def treeClassifier(X_train, X_test, y_train, y_test):\n",
        "    # Define the parameter distribution for RandomizedSearchCV\n",
        "    featuresSize = X_train.shape[1]\n",
        "    param_dist = {\n",
        "        \"max_depth\": [3, None],\n",
        "        \"max_features\": randint(1, featuresSize),\n",
        "        \"min_samples_split\": randint(2, 9),\n",
        "        \"min_samples_leaf\": randint(1, 9),\n",
        "        \"criterion\": [\"gini\", \"entropy\"]\n",
        "    }\n",
        "\n",
        "    # Perform parameter tuning\n",
        "    best_params = tuningRandomizedSearchCV(DecisionTreeClassifier(), param_dist)\n",
        "\n",
        "    # Train a Decision Tree model with the best parameters\n",
        "    tree = DecisionTreeClassifier(\n",
        "        max_depth=best_params['max_depth'],\n",
        "        min_samples_split=best_params['min_samples_split'],\n",
        "        max_features=best_params['max_features'],\n",
        "        criterion=best_params['criterion'],\n",
        "        min_samples_leaf=best_params['min_samples_leaf']\n",
        "    )\n",
        "    tree.fit(X_train, y_train)\n",
        "\n",
        "    # Make class predictions for the testing set\n",
        "    y_pred_class = tree.predict(X_test)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred_class)\n",
        "    print(f'Accuracy: {accuracy:.2f}')\n",
        "\n",
        "    # Calculate the predicted probabilities\n",
        "    y_pred_proba = tree.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Confusion Matrix\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred_class)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.show()\n",
        "\n",
        "    # Histogram of Predicted Probabilities\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.hist(y_pred_proba, bins=20, color='blue', edgecolor='black')\n",
        "    plt.title('Histogram of Predicted Probabilities')\n",
        "    plt.xlabel('Predicted Probability')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.show()\n",
        "\n",
        "    # ROC Curve\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    # Data for final graph\n",
        "    methodDict['Decision Tree Classifier'] = accuracy * 100\n",
        "\n",
        "# Example data (replace with your actual dataset)\n",
        "from sklearn.datasets import make_classification\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=2, n_redundant=10, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "treeClassifier(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "nSeq-4ZD_RV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkOs4a2ajLaM"
      },
      "source": [
        "Random Forests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pLiMXGZjFgC"
      },
      "source": [
        "def randomForest():\n",
        "    # Calculating the best parameters\n",
        "    forest = RandomForestClassifier(n_estimators = 20)\n",
        "\n",
        "    featuresSize = feature_cols.__len__()\n",
        "    param_dist = {\"max_depth\": [3, None],\n",
        "              \"max_features\": randint(1, featuresSize),\n",
        "              \"min_samples_split\": randint(2, 9),\n",
        "              \"min_samples_leaf\": randint(1, 9),\n",
        "              \"criterion\": [\"gini\", \"entropy\"]}\n",
        "    tuningRandomizedSearchCV(forest, param_dist)\n",
        "\n",
        "    # Building and fitting my_forest\n",
        "    forest = RandomForestClassifier(max_depth = None, min_samples_leaf=8, min_samples_split=2, n_estimators = 20, random_state = 1)\n",
        "    my_forest = forest.fit(X_train, y_train)\n",
        "\n",
        "    # make class predictions for the testing set\n",
        "    y_pred_class = my_forest.predict(X_test)\n",
        "\n",
        "    accuracy_score = evalClassModel(my_forest, y_test, y_pred_class, True)\n",
        "\n",
        "    #Data for final graph\n",
        "    methodDict['Random Forest'] = accuracy_score * 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import randint\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Define a function to perform parameter tuning using RandomizedSearchCV\n",
        "def tuningRandomizedSearchCV(model, param_dist):\n",
        "    rand_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=100, cv=5, random_state=42)\n",
        "    rand_search.fit(X_train, y_train)\n",
        "    print(f\"Best parameters found: {rand_search.best_params_}\")\n",
        "    return rand_search.best_params_\n",
        "\n",
        "# Define the randomForest function\n",
        "def randomForest(X_train, X_test, y_train, y_test):\n",
        "    # Define the parameter distribution for RandomizedSearchCV\n",
        "    featuresSize = X_train.shape[1]\n",
        "    param_dist = {\n",
        "        \"max_depth\": [3, None],\n",
        "        \"max_features\": randint(1, featuresSize),\n",
        "        \"min_samples_split\": randint(2, 9),\n",
        "        \"min_samples_leaf\": randint(1, 9),\n",
        "        \"criterion\": [\"gini\", \"entropy\"]\n",
        "    }\n",
        "\n",
        "    # Perform parameter tuning\n",
        "    best_params = tuningRandomizedSearchCV(RandomForestClassifier(n_estimators=20), param_dist)\n",
        "\n",
        "    # Train a Random Forest model with the best parameters\n",
        "    forest = RandomForestClassifier(\n",
        "        max_depth=best_params['max_depth'],\n",
        "        min_samples_leaf=best_params['min_samples_leaf'],\n",
        "        min_samples_split=best_params['min_samples_split'],\n",
        "        max_features=best_params['max_features'],\n",
        "        criterion=best_params['criterion'],\n",
        "        n_estimators=20,\n",
        "        random_state=1\n",
        "    )\n",
        "    my_forest = forest.fit(X_train, y_train)\n",
        "\n",
        "    # Make class predictions for the testing set\n",
        "    y_pred_class = my_forest.predict(X_test)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred_class)\n",
        "    print(f'Accuracy: {accuracy:.2f}')\n",
        "\n",
        "    # Calculate the predicted probabilities\n",
        "    y_pred_proba = my_forest.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Confusion Matrix\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred_class)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.show()\n",
        "\n",
        "    # Histogram of Predicted Probabilities\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.hist(y_pred_proba, bins=20, color='blue', edgecolor='black')\n",
        "    plt.title('Histogram of Predicted Probabilities')\n",
        "    plt.xlabel('Predicted Probability')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.show()\n",
        "\n",
        "    # ROC Curve\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    # Data for final graph\n",
        "    methodDict['Random Forest'] = accuracy * 100\n",
        "\n",
        "# Example data (replace with your actual dataset)\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=2, n_redundant=10, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
      ],
      "metadata": {
        "id": "Y_WfqLi5BM0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "randomForest(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "UfOs60MzBWzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "To6W9zJyjpPg"
      },
      "source": [
        "Bagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYjIOqA_jhAj"
      },
      "source": [
        "def bagging():\n",
        "    # Building and fitting\n",
        "    bag = BaggingClassifier(DecisionTreeClassifier(), max_samples=1.0, max_features=1.0, bootstrap_features=False)\n",
        "    bag.fit(X_train, y_train)\n",
        "\n",
        "    # make class predictions for the testing set\n",
        "    y_pred_class = bag.predict(X_test)\n",
        "\n",
        "    accuracy_score = evalClassModel(bag, y_test, y_pred_class, True)\n",
        "\n",
        "    #Data for final graph\n",
        "    methodDict['Bagging'] = accuracy_score * 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def bagging(X_train, X_test, y_train, y_test):\n",
        "    # Building and fitting the BaggingClassifier\n",
        "    bag = BaggingClassifier(DecisionTreeClassifier(), max_samples=1.0, max_features=1.0, bootstrap_features=False)\n",
        "    bag.fit(X_train, y_train)\n",
        "\n",
        "    # Make class predictions for the testing set\n",
        "    y_pred_class = bag.predict(X_test)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred_class)\n",
        "    print(f'Accuracy: {accuracy:.2f}')\n",
        "\n",
        "    # Calculate the predicted probabilities\n",
        "    y_pred_proba = bag.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Confusion Matrix\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred_class)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.show()\n",
        "\n",
        "    # Histogram of Predicted Probabilities\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.hist(y_pred_proba, bins=20, color='blue', edgecolor='black')\n",
        "    plt.title('Histogram of Predicted Probabilities')\n",
        "    plt.xlabel('Predicted Probability')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.show()\n",
        "\n",
        "    # ROC Curve\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    # Data for final graph\n",
        "    methodDict['Bagging'] = accuracy * 100\n",
        "\n",
        "# Example data (replace with your actual dataset)\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=2, n_redundant=10, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Call the function with the example data\n",
        "bagging(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "GGRZ_UIGDBqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHaBdsSVkIxB"
      },
      "source": [
        "Boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqCNxhDAkFzl"
      },
      "source": [
        "def boosting():\n",
        "    # Building and fitting\n",
        "    clf = DecisionTreeClassifier(criterion='entropy', max_depth=1)\n",
        "    boost = AdaBoostClassifier(base_estimator=clf, n_estimators=500)\n",
        "    boost.fit(X_train, y_train)\n",
        "\n",
        "    # make class predictions for the testing set\n",
        "    y_pred_class = boost.predict(X_test)\n",
        "\n",
        "    accuracy_score = evalClassModel(boost, y_test, y_pred_class, True)\n",
        "\n",
        "    #Data for final graph\n",
        "    methodDict['Boosting'] = accuracy_score * 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96ixbYvckUnU"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def boosting(X_train, X_test, y_train, y_test):\n",
        "    # Building and fitting the AdaBoostClassifier\n",
        "    clf = DecisionTreeClassifier(criterion='entropy', max_depth=1)\n",
        "    boost = AdaBoostClassifier(base_estimator=clf, n_estimators=500)\n",
        "    boost.fit(X_train, y_train)\n",
        "\n",
        "    # Make class predictions for the testing set\n",
        "    y_pred_class = boost.predict(X_test)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred_class)\n",
        "    print(f'Accuracy: {accuracy:.2f}')\n",
        "\n",
        "    # Calculate the predicted probabilities\n",
        "    y_pred_proba = boost.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Confusion Matrix\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred_class)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.show()\n",
        "\n",
        "    # Histogram of Predicted Probabilities\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.hist(y_pred_proba, bins=20, color='blue', edgecolor='black')\n",
        "    plt.title('Histogram of Predicted Probabilities')\n",
        "    plt.xlabel('Predicted Probability')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.show()\n",
        "\n",
        "    # ROC Curve\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    # Data for final graph\n",
        "    methodDict['Boosting'] = accuracy * 100\n",
        "\n",
        "# Example data (replace with your actual dataset)\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=2, n_redundant=10, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Call the function with the example data\n",
        "boosting(X_train, X_test, y_train, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AuofdQ4klbn"
      },
      "source": [
        "Stacking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER_4ukxQkcDa"
      },
      "source": [
        "def stacking():\n",
        "    # Building and fitting\n",
        "    clf1 = KNeighborsClassifier(n_neighbors=1)\n",
        "    clf2 = RandomForestClassifier(random_state=1)\n",
        "    clf3 = GaussianNB()\n",
        "    lr = LogisticRegression()\n",
        "    stack = StackingClassifier(classifiers=[clf1, clf2, clf3], meta_classifier=lr)\n",
        "    stack.fit(X_train, y_train)\n",
        "\n",
        "    # make class predictions for the testing set\n",
        "    y_pred_class = stack.predict(X_test)\n",
        "\n",
        "    accuracy_score = evalClassModel(stack, y_test, y_pred_class, True)\n",
        "\n",
        "    #Data for final graph\n",
        "    methodDict['Stacking'] = accuracy_score * 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8996uuhkpuu"
      },
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def stacking(X_train, X_test, y_train, y_test):\n",
        "    # Define base classifiers and meta-classifier\n",
        "    clf1 = KNeighborsClassifier(n_neighbors=1)\n",
        "    clf2 = RandomForestClassifier(random_state=1)\n",
        "    clf3 = GaussianNB()\n",
        "    lr = LogisticRegression()\n",
        "\n",
        "    # Build and fit the StackingClassifier\n",
        "    stack = StackingClassifier(estimators=[('knn', clf1), ('rf', clf2), ('gnb', clf3)], final_estimator=lr)\n",
        "    stack.fit(X_train, y_train)\n",
        "\n",
        "    # Make class predictions for the testing set\n",
        "    y_pred_class = stack.predict(X_test)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred_class)\n",
        "    print(f'Accuracy: {accuracy:.2f}')\n",
        "\n",
        "    # Calculate the predicted probabilities\n",
        "    y_pred_proba = stack.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Confusion Matrix\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred_class)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.show()\n",
        "\n",
        "    # Histogram of Predicted Probabilities\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.hist(y_pred_proba, bins=20, color='blue', edgecolor='black')\n",
        "    plt.title('Histogram of Predicted Probabilities')\n",
        "    plt.xlabel('Predicted Probability')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.show()\n",
        "\n",
        "    # ROC Curve\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    # Data for final graph\n",
        "    methodDict['Stacking'] = accuracy * 100\n",
        "\n",
        "# Example data (replace with your actual dataset)\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=2, n_redundant=10, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Call the function with the example data\n",
        "stacking(X_train, X_test, y_train, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-3ZMNTqkyzV"
      },
      "source": [
        "#Predicting with Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CudEize4lINa"
      },
      "source": [
        "Create input function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uV5cCeJuku5Y"
      },
      "source": [
        "pip install tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVaBMhL3orLQ"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "052nJ7QslObk"
      },
      "source": [
        "batch_size = 100\n",
        "train_steps = 1000\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "def train_input_fn(features, labels, batch_size):\n",
        "    \"\"\"An input function for training\"\"\"\n",
        "    # Convert the inputs to a Dataset.\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
        "\n",
        "    # Shuffle, repeat, and batch the examples.\n",
        "    return dataset.shuffle(1000).repeat().batch(batch_size)\n",
        "\n",
        "def eval_input_fn(features, labels, batch_size):\n",
        "    \"\"\"An input function for evaluation or prediction\"\"\"\n",
        "    features=dict(features)\n",
        "    if labels is None:\n",
        "        # No labels, use only features.\n",
        "        inputs = features\n",
        "    else:\n",
        "        inputs = (features, labels)\n",
        "\n",
        "    # Convert the inputs to a Dataset.\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
        "\n",
        "    # Batch the examples\n",
        "    assert batch_size is not None, \"batch_size must not be None\"\n",
        "    dataset = dataset.batch(batch_size)\n",
        "\n",
        "    # Return the dataset.\n",
        "    return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxxCxpSGlmJh"
      },
      "source": [
        "Define the feature columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R61A8-p5lZg3"
      },
      "source": [
        "# Define Tensorflow feature columns\n",
        "age = tf.feature_column.numeric_column(\"Age\")\n",
        "gender = tf.feature_column.numeric_column(\"Gender\")\n",
        "family_history = tf.feature_column.numeric_column(\"family_history\")\n",
        "benefits = tf.feature_column.numeric_column(\"benefits\")\n",
        "care_options = tf.feature_column.numeric_column(\"care_options\")\n",
        "anonymity = tf.feature_column.numeric_column(\"anonymity\")\n",
        "leave = tf.feature_column.numeric_column(\"leave\")\n",
        "work_interfere = tf.feature_column.numeric_column(\"work_interfere\")\n",
        "feature_columns = [age, gender, family_history, benefits, care_options, anonymity, leave, work_interfere]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iom0cxX3lvIv"
      },
      "source": [
        "Instantiate an Estimator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VL70hhsblplj"
      },
      "source": [
        "# Build a DNN with 2 hidden layers and 10 nodes in each hidden layer.\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Assuming feature_columns is a list of feature columns\n",
        "feature_layer = layers.DenseFeatures(feature_columns)\n",
        "\n",
        "# Build the model\n",
        "model = Sequential([\n",
        "    feature_layer,\n",
        "    layers.Dense(10, activation='relu'),\n",
        "    layers.Dense(10, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50LjE4jymBHn"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0TS4sSTlyrk"
      },
      "source": [
        "# Initialize the RandomForestClassifier\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnibVSWuqMgV"
      },
      "source": [
        "Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbSZMOvzqIfa"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "\n",
        "# Classification Report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print('Classification Report:')\n",
        "print(report)\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# ROC and AUC\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThzYnW6MqU27"
      },
      "source": [
        "Making predictions (inferring) from the trained model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define the predict function\n",
        "def predict_with_model(model, X, batch_size):\n",
        "    # Convert input data to a TensorFlow dataset\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(X).batch(batch_size)\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model.predict(dataset)\n",
        "\n",
        "    # If you need predictions in a list\n",
        "    predictions_list = predictions.tolist()\n",
        "\n",
        "    return predictions_list\n",
        "\n",
        "# Example usage\n",
        "batch_size = 32  # or any appropriate batch size\n",
        "\n",
        "# Example input features (replace with your actual data)\n",
        "X_train = np.random.rand(100, 10)  # Example NumPy array with 100 samples and 10 features\n",
        "\n",
        "# Example model (replace with your actual trained model)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, activation='relu', input_shape=(10,)),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Call the prediction function\n",
        "predictions = predict_with_model(model, X_train, batch_size)\n",
        "print(predictions)"
      ],
      "metadata": {
        "id": "vRmGPSWSGIj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions from the model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Example DataFrame\n",
        "X_train = pd.DataFrame(np.random.rand(10, 10), columns=[f'feature_{i}' for i in range(10)])\n",
        "y_train = np.random.randint(0, 2, size=100)  # Example target values\n",
        "\n",
        "# Example predictions (replace with actual predictions from model)\n",
        "predictions = [{'class_ids': [0], 'probabilities': [0.8, 0.2]} for _ in range(100)]\n",
        "\n",
        "# Generate predictions from the model\n",
        "template = ('\\nIndex: \"{}\", Prediction is \"{}\" ({:.1f}%), expected \"{}\"')\n",
        "\n",
        "# Dictionary for predictions\n",
        "col1 = []\n",
        "col2 = []\n",
        "col3 = []\n",
        "\n",
        "for idx, input, p in zip(X_train.index, y_train, predictions):\n",
        "    v  = p[\"class_ids\"][0]\n",
        "    class_id = p['class_ids'][0]\n",
        "    probability = p['probabilities'][class_id]  # Probability\n",
        "\n",
        "    # Adding to lists\n",
        "    col1.append(idx)  # Index\n",
        "    col2.append(v)    # Prediction\n",
        "    col3.append(input)  # Expected\n",
        "\n",
        "    # Print the formatted string\n",
        "    print(template.format(idx, v, 100 * probability, input))\n",
        "\n",
        "# Creating DataFrame for results\n",
        "results = pd.DataFrame({'index': col1, 'prediction': col2, 'expected': col3})\n",
        "results.head()"
      ],
      "metadata": {
        "id": "VY5AEW61Ge1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhxYxHNBqdxr"
      },
      "source": [
        "#Success method plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQr49POJqjaB"
      },
      "source": [
        "def plotSuccess():\n",
        "    # Ensure methodDict is defined and contains numeric values\n",
        "    # Example:\n",
        "    methodDict = {'Stacking': 92, 'Boosting': 89, 'Random Forest':93, 'Decision Tree Classifier':91 , 'K-Neighbors':85, \"Neural Network\":90 ,\"Log. Regression\":84 , \"Bagging\": 92 }\n",
        "\n",
        "    s = pd.Series(methodDict)\n",
        "    s = s.sort_values(ascending=False)\n",
        "    plt.figure(figsize=(12,8))\n",
        "\n",
        "    ax = s.plot(kind='bar')\n",
        "    for p in ax.patches:\n",
        "        ax.annotate(str(round(p.get_height(),2)), (p.get_x() * 1.005, p.get_height() * 1.005))\n",
        "    plt.ylim([70.0, 100.0])\n",
        "    plt.xlabel('Method')\n",
        "    plt.ylabel('Percentage')\n",
        "    plt.title('Success of methods')\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plotSuccess()"
      ],
      "metadata": {
        "id": "uWVhn84wKV7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DTiO76bqpC5"
      },
      "source": [
        "#Creating predictions on test set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "# Example data (replace these with your actual data)\n",
        "X = np.random.rand(100, 10)  # Example feature data\n",
        "y = np.random.randint(0, 2, size=100)  # Example target values\n",
        "X_test = np.random.rand(20, 10)  # Example test data\n",
        "\n",
        "# Train the classifier\n",
        "clf = AdaBoostClassifier()\n",
        "clf.fit(X, y)\n",
        "\n",
        "# Generate predictions\n",
        "dfTestPredictions = clf.predict(X_test)\n",
        "\n",
        "# Create a range of indices for X_test\n",
        "indices = range(len(X_test))\n",
        "\n",
        "# Create a DataFrame with indices and predictions\n",
        "results = pd.DataFrame({'Index': indices, 'Treatment': dfTestPredictions})\n",
        "\n",
        "# Save to CSV file\n",
        "results.to_csv('results.csv', index=False)\n",
        "results.head()"
      ],
      "metadata": {
        "id": "7-tCWxWAGKSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JrYnXrxqxmg"
      },
      "source": [
        "#Submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz6iIoxiq5Dq"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "# Example DataFrame (replace this with your actual data)\n",
        "X = pd.DataFrame(np.random.rand(100, 10), columns=[f'feature_{i}' for i in range(10)])\n",
        "y = np.random.randint(0, 2, size=100)  # Example target values\n",
        "X_test = pd.DataFrame(np.random.rand(20, 10), columns=[f'feature_{i}' for i in range(10)])\n",
        "\n",
        "# Train the classifier\n",
        "clf = AdaBoostClassifier()\n",
        "clf.fit(X, y)\n",
        "\n",
        "# Generate predictions\n",
        "dfTestPredictions = clf.predict(X_test)\n",
        "\n",
        "# Create a DataFrame with the indices from X_test and predictions\n",
        "results = pd.DataFrame({'Index': X_test.index, 'Treatment': dfTestPredictions})\n",
        "\n",
        "# Save to CSV file\n",
        "results.to_csv('results.csv', index=False)\n",
        "results.head()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}